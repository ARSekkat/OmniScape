# __The OmniScape Dataset__

## News
! UNDER CONSTRUCTION ! ! UNDER CONSTRUCTION ! ! UNDER CONSTRUCTION !

## Paper (Submitted to RA-L and ICRA)

### __The OmniScape Dataset__

__Ahmed Rida Sekkat__, Normandie Univ, UNIROUEN, LITIS, Rouen, France, ahmed-rida.sekkat@univ-rouen.fr  
Yohan Dupuis, Normandie Univ, UNIROUEN, ESIGELEC, IRSEEM, Rouen, France  
Pascal Vasseur, Normandie Univ, UNIROUEN, LITIS, Rouen, France  
Paul Honeine, Normandie Univ, UNIROUEN, LITIS, Rouen, France

### Abstract
Despite the utility and benefits of omnidirectional images in robotics and automotive applications, there are no datasets of omnidirectional images available with semantic segmentation, depth map, and dynamic properties. This is due to the time cost and human effort required to annotate ground truth images. This paper presents a framework for generating omnidirectional images using images that are acquired from a virtual environment. For this purpose, we demonstrate the relevance of the proposed framework on two well-known simulators: CARLA simulator, which is an open-source simulator for autonomous driving research, and Grand Theft Auto V (GTA V), which is a very high quality video game. We explain in details the generated OmniScape dataset, which includes stereo fisheye and catadioptric images acquired from the two front sides of a motorcycle, including semantic segmentation, depth map, intrinsic parameters of the cameras and the dynamic parameters of the motorcycle. It is worth noting that the case of two-wheeled vehicles is more challenging than cars due to the specific dynamic of these vehicles.

![](images/OmniScape.png )


## Teasers

### CARLA simulator: 

__1.__ Two sequences of fisheye stereo images, divided on subsequences where is shown the depth map then the semantic segmentation. The cameras are placed on the two front sides of a motorcycle.
[![](https://img.youtube.com/vi/lGUZWL54UVA/0.jpg)](https://www.youtube.com/watch?v=lGUZWL54UVA)
[![](https://img.youtube.com/vi/mkygXr6C_ls/0.jpg)](https://www.youtube.com/watch?v=mkygXr6C_ls)

__2.__ Two sequences of catadioptric stereo images, divided on subsequences where is shown the depth map then the semantic segmentation. The cameras are placed on the two front sides of a motorcycle.
[![](https://img.youtube.com/vi/lCeCnO9cupk/0.jpg)](https://www.youtube.com/watch?v=lCeCnO9cupk)
[![](https://img.youtube.com/vi/98G5GLOPt9c/0.jpg)](https://www.youtube.com/watch?v=98G5GLOPt9c)


*The images are provided in different weather conditions:*
![](images/WeatherChanges.gif)

### GTA V:
__1.__ A sequence of fisheye stereo images, divided on subsequences where is shown the depth map then the semantic segmentation. The cameras are placed on the two front sides of a motorcycle.
[![](https://img.youtube.com/vi/TndNQuGZv4A/0.jpg)](https://www.youtube.com/watch?v=TndNQuGZv4A)

__2.__ A sequence of catadioptric stereo images, divided on subsequences where is shown the depth map then the semantic segmentation. The cameras are placed on the roof of a car, positioned one above the other.  
[![](https://img.youtube.com/vi/L2JfevOPlTg/0.jpg)](https://www.youtube.com/watch?v=L2JfevOPlTg)

## Dataset Release
The dataset and tools will be provided in stages as soon as the article is published.  
  
If you are interested in The OmniScape Dataset, please fulfill [This Form](https://forms.gle/XSrUSsnwGPcyhv2B9) to receive the first release.




**This work was supported by a RIN grant, RÃ©gion Normandie, France*
